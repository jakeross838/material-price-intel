---
phase: 04-review-ui
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - material-price-intel/supabase/migrations/007_extraction_trigger.sql
  - material-price-intel/supabase/migrations/008_approved_status_and_rpc.sql
  - material-price-intel/src/hooks/useUploadDocument.ts
autonomous: true

must_haves:
  truths:
    - "Uploading a PDF automatically triggers extraction without client-side Edge Function invoke"
    - "Documents can have an 'approved' status after human review"
    - "approve_quote RPC marks quote as verified and document as approved in one call"
  artifacts:
    - path: "material-price-intel/supabase/migrations/007_extraction_trigger.sql"
      provides: "Database trigger that auto-invokes extraction on document INSERT"
      contains: "CREATE OR REPLACE FUNCTION"
    - path: "material-price-intel/supabase/migrations/008_approved_status_and_rpc.sql"
      provides: "Approved status + approve_quote + update_quote_and_line_items RPCs"
      contains: "approve_quote"
    - path: "material-price-intel/src/hooks/useUploadDocument.ts"
      provides: "Upload hook with client-side Edge Function invoke removed"
  key_links:
    - from: "documents INSERT"
      to: "process-document Edge Function"
      via: "database trigger using pg_net or Supabase webhook"
      pattern: "net.http_post|supabase_functions.http_request"
    - from: "approve_quote RPC"
      to: "quotes.is_verified + documents.status"
      via: "SQL function"
      pattern: "is_verified.*TRUE.*approved"
---

<objective>
Fix the broken auto-extraction trigger and add database infrastructure for the review/approve workflow.

Purpose: The current client-side `supabase.functions.invoke()` call silently fails because Edge Functions require service role auth, not the anon key. Documents stay "pending" forever. This plan replaces the broken client-side trigger with a reliable database-level trigger. It also adds the `approved` document status and review RPCs needed by the review UI.

Output: Two SQL migrations (007 for extraction trigger, 008 for approve infrastructure), and an updated upload hook with the broken invoke removed.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-extraction/03-03-SUMMARY.md

Key files:
@material-price-intel/src/hooks/useUploadDocument.ts
@material-price-intel/supabase/migrations/002_schema.sql
@material-price-intel/supabase/migrations/006_job_queue.sql
@material-price-intel/supabase/functions/process-document/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create database trigger for auto-extraction + remove broken client-side invoke</name>
  <files>
    material-price-intel/supabase/migrations/007_extraction_trigger.sql
    material-price-intel/src/hooks/useUploadDocument.ts
  </files>
  <action>
Create migration `007_extraction_trigger.sql` that sets up a database trigger to automatically invoke the `process-document` Edge Function when a new document is inserted with status 'pending'.

**Approach — use Supabase's `supabase_functions.http_request` (Database Webhooks):**

Supabase provides built-in support for triggering Edge Functions from database triggers via the `supabase_functions` schema. This is the recommended approach because:
- It uses the service role key internally (no auth issues)
- It's asynchronous (non-blocking)
- It's built into Supabase (no pg_net extension needed)

Create a trigger function and trigger:

```sql
-- Enable the pg_net extension (required for HTTP calls from PostgreSQL)
CREATE EXTENSION IF NOT EXISTS pg_net WITH SCHEMA extensions;

-- Trigger function that calls the Edge Function via pg_net
CREATE OR REPLACE FUNCTION trigger_document_extraction()
RETURNS TRIGGER AS $$
DECLARE
  edge_function_url TEXT;
  service_role_key TEXT;
BEGIN
  -- Only trigger for new documents with 'pending' status
  IF NEW.status = 'pending' THEN
    -- Build the Edge Function URL
    edge_function_url := current_setting('app.settings.supabase_url', true)
      || '/functions/v1/process-document';
    service_role_key := current_setting('app.settings.service_role_key', true);

    -- Make async HTTP POST to Edge Function
    PERFORM net.http_post(
      url := edge_function_url,
      body := jsonb_build_object('document_id', NEW.id),
      headers := jsonb_build_object(
        'Content-Type', 'application/json',
        'Authorization', 'Bearer ' || service_role_key
      )
    );
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

CREATE TRIGGER on_document_insert_trigger_extraction
  AFTER INSERT ON documents
  FOR EACH ROW
  EXECUTE FUNCTION trigger_document_extraction();
```

**IMPORTANT:** The `pg_net` approach requires the `pg_net` extension to be enabled in Supabase. Check if it's available. If `pg_net` is not available or `current_setting` for service role key is not configured, use the **alternative approach**: create the trigger via the Supabase Dashboard's Database Webhooks feature instead (which is a built-in GUI for creating these triggers). In that case, the migration should include a comment documenting the manual setup step, and the task becomes a checkpoint.

**HOWEVER**, the simpler and more reliable approach for Supabase specifically is to use the **Database Webhooks** feature in the Supabase Dashboard, which does exactly this without needing pg_net or storing secrets in PostgreSQL settings. Since this is a single-user app and the webhook can be configured once:

**Recommended approach for the migration file:**
1. Create the migration file with a SQL comment block explaining that the extraction trigger is configured via Supabase Dashboard Database Webhooks (not raw SQL) because it automatically handles service role auth
2. Include a `-- MANUAL SETUP` section documenting the webhook configuration:
   - Table: `documents`
   - Event: `INSERT`
   - Type: `Supabase Edge Function`
   - Function: `process-document`
   - HTTP method: POST
   - Headers: Content-Type: application/json
   - Body: `{"document_id": "{{id}}"}`

**ACTUALLY — simplest reliable approach:** Use a Supabase Database Webhook configured via SQL. Supabase projects on the hosted platform have `supabase_functions.http_request` available. Create the trigger using that:

```sql
CREATE OR REPLACE FUNCTION trigger_document_extraction()
RETURNS TRIGGER AS $$
BEGIN
  IF NEW.status = 'pending' THEN
    PERFORM
      net.http_post(
        url => (SELECT decrypted_secret FROM vault.decrypted_secrets WHERE name = 'supabase_url') || '/functions/v1/process-document',
        headers => jsonb_build_object(
          'Content-Type', 'application/json',
          'Authorization', 'Bearer ' || (SELECT decrypted_secret FROM vault.decrypted_secrets WHERE name = 'service_role_key')
        ),
        body => jsonb_build_object('document_id', NEW.id)::text
      );
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**FINAL DECISION — keep it simple:** Since we know the Supabase URL and the service role key is already configured as a secret, the MOST PRACTICAL approach is to write the migration using `pg_net` with hardcoded Supabase URL (it's not a secret — it's in the frontend .env) and the service role key from vault. BUT vault access may be complex.

**USE THIS APPROACH:** Write the migration to enable `pg_net`, create a trigger function that calls `net.http_post` with the Supabase project URL hardcoded (since it's public: `https://xgpjwphtfmbvoqtvete.supabase.co`) and the service role key passed via `Authorization: Bearer` header. Since the service role key should NOT be hardcoded in SQL, use one of:
1. Supabase vault: `SELECT decrypted_secret FROM vault.decrypted_secrets WHERE name = 'service_role_key'`
2. Or simply pass a placeholder and document that the user must set it via the Dashboard

**SIMPLEST CORRECT APPROACH:** The migration should:
1. Enable `pg_net` extension
2. Create a wrapper function that uses `net.http_post`
3. Use the Supabase project URL (public, from STATE.md: `xgpjwphtfmbvoqtvete.supabase.co`)
4. For the service role key, read it from `current_setting('supabase.service_role_key', true)` which Supabase sets automatically in Edge Functions but NOT in SQL. So instead, store it in vault.

**OK let me stop overthinking. Here's the actual implementation:**

The migration file should:
1. `CREATE EXTENSION IF NOT EXISTS pg_net WITH SCHEMA extensions;`
2. Create a trigger function `trigger_document_extraction()` that fires on INSERT to documents table when status = 'pending'
3. Inside the function, call `net.http_post()` to invoke the Edge Function
4. For the URL, use the project URL directly: `'https://xgpjwphtfmbvoqtvete.supabase.co/functions/v1/process-document'`
5. For auth, use the ANON key in Authorization header (the Edge Function itself creates a service role client internally, so it doesn't matter which key invokes it — the Edge Function already uses `SUPABASE_SERVICE_ROLE_KEY` from Deno.env internally)

**Wait — re-reading the Edge Function code:** The Edge Function creates its own service role Supabase client at line 265. The incoming request auth header is NOT used for database operations. The Edge Function just needs to be callable. On Supabase hosted, Edge Functions can be called with ANY valid JWT (anon or service role). The issue with the client-side call was likely a CORS or networking issue, not an auth issue per se.

**THE ACTUAL FIX:** Use `pg_net` to call the Edge Function with the anon key (which is public anyway). The Edge Function handles its own auth internally. This is the simplest approach.

Create the migration:

```sql
CREATE EXTENSION IF NOT EXISTS pg_net WITH SCHEMA extensions;

CREATE OR REPLACE FUNCTION public.trigger_document_extraction()
RETURNS TRIGGER AS $$
BEGIN
  IF NEW.status = 'pending' THEN
    PERFORM extensions.http_post(
      url := 'https://xgpjwphtfmbvoqtvete.supabase.co/functions/v1/process-document',
      body := jsonb_build_object('document_id', NEW.id),
      headers := '{"Content-Type": "application/json", "Authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."}'::jsonb
    );
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

CREATE TRIGGER on_document_created_extract
  AFTER INSERT ON documents
  FOR EACH ROW
  EXECUTE FUNCTION public.trigger_document_extraction();
```

**NO — don't hardcode keys in migrations.** Here is the ACTUAL correct approach:

Use Supabase's Database Webhooks. In the Supabase Dashboard:
1. Go to Database > Webhooks
2. Create a webhook:
   - Name: `trigger-extraction`
   - Table: `documents`
   - Events: INSERT
   - Type: Supabase Edge Functions
   - Edge Function: `process-document`
   - HTTP Method: POST
   - Additional headers: none needed (Dashboard handles auth)

**For the migration file**: Write a COMMENT-ONLY migration documenting this setup, since Supabase Database Webhooks are configured via the Dashboard, not SQL migrations.

**For useUploadDocument.ts**: Remove the fire-and-forget `supabase.functions.invoke()` block (lines 101-109). The database webhook will handle triggering extraction automatically.

This is the cleanest approach: the webhook is managed by Supabase infrastructure, handles auth automatically, and requires no secrets in SQL.
  </action>
  <verify>
    1. `007_extraction_trigger.sql` exists with documentation of the webhook setup
    2. `useUploadDocument.ts` no longer contains `supabase.functions.invoke('process-document'`
    3. `npm run build` passes in `material-price-intel/`
    4. The migration file includes clear instructions for Dashboard webhook configuration
  </verify>
  <done>
    The broken client-side Edge Function invoke is removed from useUploadDocument.ts. A migration file documents the Database Webhook configuration that replaces it. The upload hook returns cleanly after creating the document record, and extraction is triggered by the database-level webhook.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add approved status and review RPCs</name>
  <files>
    material-price-intel/supabase/migrations/008_approved_status_and_rpc.sql
    material-price-intel/src/lib/types.ts
  </files>
  <action>
Create migration `008_approved_status_and_rpc.sql` that:

1. **Add 'approved' to documents status CHECK constraint:**
```sql
ALTER TABLE documents DROP CONSTRAINT IF EXISTS documents_status_check;
ALTER TABLE documents ADD CONSTRAINT documents_status_check
  CHECK (status IN ('pending', 'processing', 'completed', 'failed', 'review_needed', 'approved'));
```

2. **Create `approve_quote` RPC** that atomically:
   - Sets `quotes.is_verified = TRUE` for the given quote_id
   - Sets the linked `documents.status = 'approved'` (find document by `documents.quote_id = p_quote_id`)
   - Sets `documents.completed_at = NOW()` if not already set
   - Returns void
   - Should be `SECURITY DEFINER` so it works through RLS

```sql
CREATE OR REPLACE FUNCTION approve_quote(p_quote_id UUID)
RETURNS VOID AS $$
BEGIN
  -- Mark quote as verified
  UPDATE quotes
  SET is_verified = TRUE
  WHERE id = p_quote_id;

  -- Mark linked document as approved
  UPDATE documents
  SET status = 'approved',
      completed_at = COALESCE(completed_at, NOW())
  WHERE quote_id = p_quote_id;
END;
$$ LANGUAGE plpgsql VOLATILE SECURITY DEFINER;
```

3. **Create `update_quote_review` RPC** for saving edits during review (updates quote fields and replaces line items):

```sql
CREATE OR REPLACE FUNCTION update_quote_review(
  p_quote_id UUID,
  p_supplier_name TEXT DEFAULT NULL,
  p_quote_number TEXT DEFAULT NULL,
  p_quote_date DATE DEFAULT NULL,
  p_project_name TEXT DEFAULT NULL,
  p_payment_terms TEXT DEFAULT NULL,
  p_valid_until DATE DEFAULT NULL,
  p_notes TEXT DEFAULT NULL,
  p_subtotal NUMERIC DEFAULT NULL,
  p_delivery_cost NUMERIC DEFAULT NULL,
  p_tax_amount NUMERIC DEFAULT NULL,
  p_tax_rate NUMERIC DEFAULT NULL,
  p_total_amount NUMERIC DEFAULT NULL,
  p_line_items JSONB DEFAULT NULL
)
RETURNS VOID AS $$
DECLARE
  v_supplier_id UUID;
  item JSONB;
  i INT := 0;
BEGIN
  -- Update quote scalar fields (only non-null params)
  UPDATE quotes SET
    quote_number = COALESCE(p_quote_number, quote_number),
    quote_date = COALESCE(p_quote_date, quote_date),
    project_name = COALESCE(p_project_name, project_name),
    payment_terms = COALESCE(p_payment_terms, payment_terms),
    valid_until = COALESCE(p_valid_until, valid_until),
    notes = COALESCE(p_notes, notes),
    subtotal = COALESCE(p_subtotal, subtotal),
    delivery_cost = COALESCE(p_delivery_cost, delivery_cost),
    tax_amount = COALESCE(p_tax_amount, tax_amount),
    tax_rate = COALESCE(p_tax_rate, tax_rate),
    total_amount = COALESCE(p_total_amount, total_amount)
  WHERE id = p_quote_id;

  -- Replace line items if provided
  IF p_line_items IS NOT NULL THEN
    DELETE FROM line_items WHERE quote_id = p_quote_id;

    FOR item IN SELECT * FROM jsonb_array_elements(p_line_items)
    LOOP
      INSERT INTO line_items (
        quote_id, raw_description, quantity, unit, unit_price,
        extended_price, discount_pct, discount_amount, line_total,
        notes, sort_order, material_id
      ) VALUES (
        p_quote_id,
        item->>'raw_description',
        (item->>'quantity')::NUMERIC,
        item->>'unit',
        (item->>'unit_price')::NUMERIC,
        (item->>'extended_price')::NUMERIC,
        (item->>'discount_pct')::NUMERIC,
        (item->>'discount_amount')::NUMERIC,
        (item->>'line_total')::NUMERIC,
        item->>'notes',
        i,
        NULL
      );
      i := i + 1;
    END LOOP;
  END IF;
END;
$$ LANGUAGE plpgsql VOLATILE SECURITY DEFINER;
```

4. **Update `src/lib/types.ts`:**
   - Add `'approved'` to the `DocumentStatus` union type:
     ```typescript
     export type DocumentStatus =
       | "pending"
       | "processing"
       | "completed"
       | "failed"
       | "review_needed"
       | "approved";
     ```
  </action>
  <verify>
    1. `008_approved_status_and_rpc.sql` exists with all three SQL statements
    2. `types.ts` DocumentStatus includes 'approved'
    3. `npm run build` passes in `material-price-intel/`
    4. The approve_quote and update_quote_review functions are syntactically valid SQL
  </verify>
  <done>
    The database supports 'approved' document status. approve_quote RPC atomically marks a quote as verified and its document as approved. update_quote_review RPC allows saving edits to quote fields and replacing line items. The TypeScript DocumentStatus type includes 'approved'.
  </done>
</task>

</tasks>

<verification>
1. Migration 007 exists and documents the Database Webhook setup for auto-extraction
2. Migration 008 exists with approved status constraint, approve_quote RPC, and update_quote_review RPC
3. useUploadDocument.ts no longer contains supabase.functions.invoke
4. types.ts DocumentStatus includes 'approved'
5. `npm run build` passes cleanly
</verification>

<success_criteria>
- The broken client-side Edge Function invoke is removed and replaced with database-level trigger documentation
- Documents table supports 'approved' status
- Two RPCs exist: approve_quote (for final approval) and update_quote_review (for saving edits)
- TypeScript types updated to include approved status
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/04-review-ui/04-01-SUMMARY.md`
</output>
